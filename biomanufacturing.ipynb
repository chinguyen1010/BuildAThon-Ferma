{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjXuUItbus6s",
        "outputId": "1cb1aa8a-81cf-456a-ec56-a2e6ceaae86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "# 1. LOAD DATA\n",
        "# Path to the CSV file\n",
        "CSV_PATH = \"realistic_bioreactor_dataset.csv\"\n",
        "\n",
        "\n",
        "def analyze_batch(csv_path: str):\n",
        "    df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"]) #Read CSV and parse timestamp as datetime\n",
        "    df = df.sort_values(\"timestamp\").reset_index(drop=True) # Sort by time and clean up\n",
        "    df = df.ffill() #Forward-fill missing values\n",
        "\n",
        "    # Ensure time_hours\n",
        "    if \"time_hours\" not in df.columns:\n",
        "        df[\"time_hours\"] = (\n",
        "            df[\"timestamp\"] - df[\"timestamp\"].min()\n",
        "        ).dt.total_seconds() / 3600.0\n",
        "\n",
        "    # 2. FEATURE ENGINEERING\n",
        "    df[\"prod_slope\"] = df[\"product_conc\"].diff() / df[\"time_hours\"].diff() # Product slope: d(product_conc)/dt\n",
        "    df[\"od_slope\"] = df[\"od600\"].diff() / df[\"time_hours\"].diff() # OD slope: d(od600)/dt\n",
        "    df[\"prod_slope_smooth\"] = df[\"prod_slope\"].rolling(5, min_periods=1).mean() # Smoothed product slope for plateau detection\n",
        "\n",
        "    # ----- Deviations from setpoints -----\n",
        "    # Temperature deviation from nominal 30Â°C\n",
        "    df[\"temp_dev\"] = df[\"temp_c\"] - 30.0\n",
        "    df[\"ph_dev\"] = df[\"pH\"] - 6.5 # pH deviation from nominal 6.5\n",
        "    # Absolute deviations for magnitude-based features\n",
        "    df[\"abs_temp_dev\"] = df[\"temp_dev\"].abs()\n",
        "    df[\"abs_ph_dev\"] = df[\"ph_dev\"].abs()\n",
        "\n",
        "    window = 5\n",
        "    # Rolling mean and std of OD600\n",
        "    df[\"od600_rm5\"] = df[\"od600\"].rolling(window, min_periods=1).mean()\n",
        "    df[\"od600_rs5\"] = df[\"od600\"].rolling(window, min_periods=1).std()\n",
        "    # Rolling mean and std of temperature\n",
        "    df[\"temp_rm5\"] = df[\"temp_c\"].rolling(window, min_periods=1).mean()\n",
        "    df[\"temp_rs5\"] = df[\"temp_c\"].rolling(window, min_periods=1).std()\n",
        "    # Rolling mean and std of pH\n",
        "    df[\"pH_rm5\"] = df[\"pH\"].rolling(window, min_periods=1).mean()\n",
        "    df[\"pH_rs5\"] = df[\"pH\"].rolling(window, min_periods=1).std()\n",
        "\n",
        "    df[\"od600_lag1\"] = df[\"od600\"].shift(1) # OD600 at previous time step\n",
        "    df[\"product_lag1\"] = df[\"product_conc\"].shift(1) # Product concentration at previous time step\n",
        "\n",
        "    #ML : feature matrix, target, train/test split, RandomForest\n",
        "    FEATURE_COLS = [\n",
        "        \"time_hours\",\n",
        "        \"od600\",\n",
        "        \"substrate_conc\",\n",
        "        \"temp_c\",\n",
        "        \"dissolved_o2\",\n",
        "        \"pH\",\n",
        "        \"prod_slope_smooth\",\n",
        "        \"od_slope\",\n",
        "        \"temp_dev\",\n",
        "        \"ph_dev\",\n",
        "        \"abs_temp_dev\",\n",
        "        \"abs_ph_dev\",\n",
        "        \"od600_rm5\",\n",
        "        \"od600_rs5\",\n",
        "        \"temp_rm5\",\n",
        "        \"temp_rs5\",\n",
        "        \"pH_rm5\",\n",
        "        \"pH_rs5\",\n",
        "        \"od600_lag1\",\n",
        "        \"product_lag1\",\n",
        "    ]\n",
        "\n",
        "    TARGET_COL = \"product_conc\"\n",
        "\n",
        "    df_ml = df.dropna(subset=FEATURE_COLS + [TARGET_COL]).reset_index(drop=True) #dropNaNs\n",
        "    # Build feature matrix X and target vector y\n",
        "    X = df_ml[FEATURE_COLS].values\n",
        "    y = df_ml[TARGET_COL].values\n",
        "    # Train/validation split\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y, test_size=0.2, shuffle=True, random_state=42\n",
        "    )\n",
        "    # RandomForest regression model\n",
        "    model = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on validation set for evaluation\n",
        "    y_pred = model.predict(X_valid)\n",
        "    # Compute model error metrics\n",
        "    mae = mean_absolute_error(y_valid, y_pred)\n",
        "    r2 = r2_score(y_valid, y_pred)\n",
        "\n",
        "    df.loc[df_ml.index, \"product_pred\"] = model.predict(X)\n",
        "\n",
        "    last_idx = df[\"product_pred\"].last_valid_index()\n",
        "    predicted_final = float(df.loc[last_idx, \"product_pred\"])\n",
        "    actual_final = float(df.loc[last_idx, \"product_conc\"])\n",
        "\n",
        "    # 5. RISK SCORE\n",
        "    # Average deviations from nominal temp and pH\n",
        "    temp_dev_mean = abs(df[\"temp_c\"].mean() - 30.0)\n",
        "    ph_dev_mean = abs(df[\"pH\"].mean() - 6.5)\n",
        "    od_drop_events = (df[\"od600\"].diff() < -0.05).sum()\n",
        "\n",
        "    total_time = df[\"time_hours\"].iloc[-1] - df[\"time_hours\"].iloc[0]\n",
        "    if total_time <= 0:\n",
        "        total_time = 1e-6\n",
        "    # Approximate oxygen depletion rate across the run\n",
        "    o2_slope = (df[\"dissolved_o2\"].iloc[0] - df[\"dissolved_o2\"].iloc[-1]) / total_time\n",
        "\n",
        "    penalty = (\n",
        "        temp_dev_mean * 10\n",
        "        + ph_dev_mean * 20\n",
        "        + od_drop_events * 10\n",
        "        + max(0, o2_slope - 5) * 5\n",
        "    )\n",
        "    # Clamp risk_score into [0, 100], where higher is healthier\n",
        "    risk_score = float(np.clip(100 - penalty, 0, 100))\n",
        "\n",
        "    risk_diagnostics = {\n",
        "        \"temp_dev\": float(temp_dev_mean),\n",
        "        \"ph_dev\": float(ph_dev_mean),\n",
        "        \"od_drop_events\": int(od_drop_events),\n",
        "        \"o2_slope\": float(o2_slope),\n",
        "    }\n",
        "\n",
        "    # 6. HARVEST TIME (generate recommendation)\n",
        "    plateau = df[(df[\"time_hours\"] > 1) & (df[\"prod_slope_smooth\"] < 0.05)]\n",
        "    # First time point where slope stays small -> recommended harvest\n",
        "    if len(plateau) > 0:\n",
        "        harvest_idx = plateau.index[0]\n",
        "    # If no plateau is found, default to last time point\n",
        "    else:\n",
        "        harvest_idx = df.index[-1]\n",
        "\n",
        "    harvest_time_hours = float(df.loc[harvest_idx, \"time_hours\"])\n",
        "    harvest_timestamp = df.loc[harvest_idx, \"timestamp\"]\n",
        "\n",
        "    # ADDITIONAL BIOPROCESS FEATURES\n",
        "    df[\"mu\"] = df[\"od600\"].pct_change() / df[\"time_hours\"].diff()\n",
        "    df[\"mu\"] = df[\"mu\"].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    df[\"doubling_time\"] = np.where(df[\"mu\"] > 0, np.log(2) / df[\"mu\"], np.nan)\n",
        "\n",
        "    conditions = [\n",
        "        df[\"od_slope\"] < 0.001,\n",
        "        df[\"od_slope\"].between(0.001, 0.03),\n",
        "        df[\"od_slope\"].between(0.03, 0.1),\n",
        "        df[\"od_slope\"] > 0.1,\n",
        "    ]\n",
        "    choices = [\"Lag\", \"Stationary\", \"Exponential\", \"Decline\"]\n",
        "    df[\"growth_phase\"] = np.select(conditions, choices, default=\"Unknown\")\n",
        "\n",
        "    df[\"oxygen_limitation\"] = df[\"dissolved_o2\"] < 10\n",
        "    df[\"substrate_empty\"] = df[\"substrate_conc\"] < 0.5\n",
        "\n",
        "    df[\"productivity\"] = df[\"product_conc\"].diff() / df[\"time_hours\"].diff()\n",
        "    df[\"productivity\"] = df[\"productivity\"].replace(\n",
        "        [np.inf, -np.inf], np.nan\n",
        "    ).fillna(0)\n",
        "\n",
        "    stability_index = 1 / (\n",
        "        df[\"temp_c\"].std() +\n",
        "        df[\"pH\"].std() +\n",
        "        df[\"od600\"].std()\n",
        "    )\n",
        "\n",
        "    peak_rate_idx = df[\"prod_slope\"].idxmax()\n",
        "    time_peak_rate = df.loc[peak_rate_idx, \"time_hours\"]\n",
        "\n",
        "    mu_max = float(df[\"mu\"].max())\n",
        "    dt_min = float(df[\"doubling_time\"].min(skipna=True)) if df[\"doubling_time\"].notna().any() else np.nan\n",
        "    sub_depletion_time = (\n",
        "        float(df.loc[df[\"substrate_empty\"], \"time_hours\"].min())\n",
        "        if (df[\"substrate_empty\"]).any()\n",
        "        else None\n",
        "    )\n",
        "    average_productivity = float(\n",
        "        df[\"product_conc\"].iloc[-1] / df[\"time_hours\"].iloc[-1]\n",
        "    )\n",
        "    o2_lim_events = int(df[\"oxygen_limitation\"].sum())\n",
        "    growth_phase_counts = df[\"growth_phase\"].value_counts().to_dict()\n",
        "\n",
        "    # 9. DASHBOARD â€“ DO NOT fig.show() in Streamlit\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1, shared_xaxes=True,\n",
        "        subplot_titles=(\"Product\", \"OD600\", \"Temp & pH\"),\n",
        "        vertical_spacing=0.08\n",
        "    )\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[\"time_hours\"], y=df[\"product_conc\"],\n",
        "        mode=\"lines+markers\", name=\"Product (actual)\"\n",
        "    ), row=1, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[\"time_hours\"], y=df[\"product_pred\"],\n",
        "        mode=\"lines\", name=\"Predicted\"\n",
        "    ), row=1, col=1)\n",
        "\n",
        "    fig.add_vline(x=harvest_time_hours, line_dash=\"dash\", line_color=\"red\")\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[\"time_hours\"], y=df[\"od600\"],\n",
        "        mode=\"lines+markers\", name=\"OD600\"\n",
        "    ), row=2, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[\"time_hours\"], y=df[\"temp_c\"],\n",
        "        mode=\"lines\", name=\"Temperature\"\n",
        "    ), row=3, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[\"time_hours\"], y=df[\"pH\"],\n",
        "        mode=\"lines\", name=\"pH\"\n",
        "    ), row=3, col=1)\n",
        "\n",
        "    fig.update_layout(height=900, width=1000, title_text=\"Fermentation Dashboard\")\n",
        "\n",
        "    # Instead of printing, RETURN everything to Streamlit\n",
        "    return {\n",
        "        \"df\": df,\n",
        "        \"predicted_final\": predicted_final,\n",
        "        \"actual_final\": actual_final,\n",
        "        \"mae\": mae,\n",
        "        \"r2\": r2,\n",
        "        \"risk_score\": risk_score,\n",
        "        \"risk_diagnostics\": risk_diagnostics,\n",
        "        \"harvest_time_hours\": harvest_time_hours,\n",
        "        \"harvest_timestamp\": harvest_timestamp,\n",
        "        \"fig\": fig,\n",
        "        \"mu_max\": mu_max,\n",
        "        \"dt_min\": dt_min,\n",
        "        \"sub_depletion_time\": sub_depletion_time,\n",
        "        \"average_productivity\": average_productivity,\n",
        "        \"o2_lim_events\": o2_lim_events,\n",
        "        \"stability_index\": float(stability_index),\n",
        "        \"time_peak_rate\": float(time_peak_rate),\n",
        "        \"growth_phase_counts\": growth_phase_counts,\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# Simple Domain Chatbot to answer question\n",
        "# ======================\n",
        "def fermentation_chatbot(user_msg: str, df):\n",
        "    \"\"\"\n",
        "    A simple Q&A chatbot that answers questions about the fermentation run.\n",
        "    \"\"\"\n",
        "\n",
        "    user_msg = user_msg.lower()\n",
        "\n",
        "    # Ask about final product / yield\n",
        "    if \"yield\" in user_msg or \"product\" in user_msg:\n",
        "        final_pred = df[\"product_pred\"].iloc[-1]\n",
        "        actual = df[\"product_conc\"].iloc[-1]\n",
        "        return f\"The predicted final product concentration is {final_pred:.2f}, and the actual final value is {actual:.2f}.\"\n",
        "\n",
        "    # Growth / OD600 question\n",
        "    if \"od600\" in user_msg or \"growth\" in user_msg:\n",
        "        od_max = df[\"od600\"].max()\n",
        "        return f\"The peak OD600 reached during the run was {od_max:.2f}.\"\n",
        "\n",
        "    # Harvest question\n",
        "    if \"harvest\" in user_msg:\n",
        "        return \"Harvest time is recommended when the smoothed product slope remains below 0.05.\"\n",
        "\n",
        "    # Growth phase\n",
        "    if \"phase\" in user_msg:\n",
        "        dist = df[\"growth_phase\"].value_counts().to_dict()\n",
        "        return f\"Growth phase distribution: {dist}\"\n",
        "\n",
        "    # Oxygen limitation\n",
        "    if \"oxygen\" in user_msg or \"o2\" in user_msg:\n",
        "        low_o2 = (df[\"dissolved_o2\"] < 10).sum()\n",
        "        return f\"Oxygen limitation occurred at {low_o2} timepoints.\"\n",
        "\n",
        "    return \"I'm not sure yet â€” try asking about yield, OD600, harvest time, oxygen limitation, or growth phase.\"\n",
        "\n",
        "# ============ STREAMLIT UI ============\n",
        "\n",
        "st.set_page_config(page_title=\"Ferma\", layout=\"wide\")\n",
        "st.title(\"Ferma\")\n",
        "\n",
        "st.sidebar.header(\"Data source\")\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload fermentation CSV\", type=[\"csv\"])\n",
        "use_sample = st.sidebar.checkbox(\n",
        "    \"Use sample dataset (realistic_bioreactor_dataset.csv)\",\n",
        "    value=True,\n",
        ")\n",
        "\n",
        "if st.sidebar.button(\"Run Analysis\", type=\"primary\"):\n",
        "    try:\n",
        "        if uploaded_file is not None and not use_sample:\n",
        "            suffix = Path(uploaded_file.name).suffix or \".csv\"\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:\n",
        "                tmp.write(uploaded_file.getvalue())\n",
        "                tmp_path = tmp.name\n",
        "            csv_path = tmp_path\n",
        "        else:\n",
        "            csv_path = CSV_PATH\n",
        "\n",
        "        result = analyze_batch(csv_path)\n",
        "\n",
        "        st.subheader(\"Batch Summary\")\n",
        "        c1, c2, c3, c4 = st.columns(4)\n",
        "        c1.metric(\"Predicted Final Product\", f\"{result['predicted_final']:.2f}\")\n",
        "        c2.metric(\"Actual Final Product\", f\"{result['actual_final']:.2f}\")\n",
        "        c3.metric(\"Risk Score (0â€“100)\", f\"{result['risk_score']:.1f}\")\n",
        "        c4.metric(\"Harvest Time (h)\", f\"{result['harvest_time_hours']:.2f}\")\n",
        "        st.caption(f\"Harvest timestamp: {result['harvest_timestamp']}\")\n",
        "\n",
        "        st.subheader(\"Model Performance\")\n",
        "        m1, m2 = st.columns(2)\n",
        "        m1.metric(\"MAE\", f\"{result['mae']:.4f}\")\n",
        "        m2.metric(\"RÂ²\", f\"{result['r2']:.4f}\")\n",
        "\n",
        "         #RAW DATA PREVIEW\n",
        "        st.subheader(\"Raw Data Preview\")\n",
        "        st.dataframe(\n",
        "            result[\"df\"].head(200),   # show up to 200 rows\n",
        "            use_container_width=True,\n",
        "            height=400,\n",
        "        )\n",
        "\n",
        "        st.subheader(\"Growth & Process Metrics\")\n",
        "        g1, g2, g3, g4 = st.columns(4)\n",
        "        g1.metric(\"Max Î¼ (1/h)\", f\"{result['mu_max']:.4f}\")\n",
        "        g2.metric(\"Min Doubling Time (h)\", f\"{result['dt_min']:.2f}\" if not np.isnan(result['dt_min']) else \"N/A\")\n",
        "        g3.metric(\"Stability Index\", f\"{result['stability_index']:.4f}\")\n",
        "        g4.metric(\"Avg Productivity (prod/hr)\", f\"{result['average_productivity']:.3f}\")\n",
        "\n",
        "        g5, g6, g7 = st.columns(3)\n",
        "        g5.metric(\"Oâ‚‚ Limitation Events\", f\"{result['o2_lim_events']}\")\n",
        "        if result[\"sub_depletion_time\"] is not None:\n",
        "            g6.metric(\"Substrate Depletion Time (h)\", f\"{result['sub_depletion_time']:.2f}\")\n",
        "        else:\n",
        "            g6.metric(\"Substrate Depletion Time (h)\", \"None\")\n",
        "        g7.metric(\"Time of Peak Production Rate (h)\", f\"{result['time_peak_rate']:.2f}\")\n",
        "\n",
        "        st.subheader(\"Growth Phase Distribution (timepoints)\")\n",
        "        st.write(result[\"growth_phase_counts\"])\n",
        "\n",
        "        st.subheader(\"Risk Diagnostics\")\n",
        "        st.write(result[\"risk_diagnostics\"])\n",
        "\n",
        "        st.subheader(\"Fermentation Dashboard\")\n",
        "        st.plotly_chart(result[\"fig\"], use_container_width=True)\n",
        "\n",
        "        #  CHATBOT INTERACTION\n",
        "        st.subheader(\"Ask Ferma (ðŸ¤– Chatbot Assistant)\")\n",
        "        user_q = st.text_input(\"Ask a question about the fermentation run:\")\n",
        "        if user_q:\n",
        "          bot_answer = fermentation_chatbot(user_q, result[\"df\"])\n",
        "          st.markdown(f\"**Ferma:** {bot_answer}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during analysis: {e}\")\n",
        "else:\n",
        "    st.info(\"Choose a data source and click **Run Analysis**.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwS_daAPCvS6",
        "outputId": "67bf6389-b4cf-4ec5-9873-366118981924"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"35WiNn8d7KVxwlFjk3gRoJBBiia_3L4Y2uVVsyT24S9MAdkgw\")\n",
        "ngrok.kill()\n",
        "\n",
        "!streamlit run app.py --server.port 8501 --server.headless true &>/dev/null &\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYjb15gS1OpO",
        "outputId": "f9a1d597-4f06-4877-a31b-ddbd4d833a22"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://duckie-romeo-uncommitting.ngrok-free.dev\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}